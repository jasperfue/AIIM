{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 77823,
          "databundleVersionId": 8553100,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) Load Data from Kaggle into Google Colab"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Hh6FhqXTu2Vx"
      }
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading aiim-emotion-classification, 18175099 bytes compressed\n",
            "[==================================================] 18175099 bytes downloaded\n",
            "Downloaded and uncompressed: aiim-emotion-classification\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'aiim-emotion-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F77823%2F8553100%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240630%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240630T152047Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dc132944ed56398baf30396cfef3e5cf8bb7295b3ce983ae3132a7a5be2bb552d36816540ea45cff2ebf4a9b537ada5aaa4ec75e7bdd411e2ce8f9b2275dce096e17f425ab9288b1263023f1e39d9027e0ba5ad106b2497936e0606abe53db33aa2bef8ca9b0a7496b42f81478a000fe1f999a175a557c90a6b362fad078f5c7f8f0e236dc9ae3c4300bc5735bce3c5f6ad1e1c4967df65a4d7283fad46333d9aa5c8bf4ccdf56a1ecb3bfcbd001c71d311daf2908f7a01efaa6b70fd5b5da336d2ec5f610a225a23b6974a519c74e4e0d219a48bf74a1e829fbd49e829cbc713a0613d0e7d7c8f90a9543154f353c1175aaaefe6d95fff94bd051cd36304a663'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "a2A_GF9Au2Vy",
        "outputId": "b7db628b-d7b5-4d09-f9ac-3acee4caec09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "collapsed": false,
        "id": "y2LOeQauu2V0"
      }
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import os\n",
        "from keras.utils import image_dataset_from_directory, load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D,  Flatten, Dense, Dropout, BatchNormalization, RandomFlip, RandomRotation, RandomZoom, RandomContrast, RandomBrightness, Rescaling, RandomTranslation, GlobalMaxPooling2D\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "id": "KKeeJQ5Pu2V0",
        "outputId": "cb6daffc-5cf3-4f15-a8f6-2267e3f904e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import of Data and Data Preprocessing\n",
        "\n",
        "### Import\n",
        "The Keras `image_dataset_from_directory` function provides the ability to load images and automatically assign labels based on their directory paths, which fits perfectly our data structure. Additionally, it allows for splitting the data into training and validation subsets and setting the batch size.\n",
        "\n",
        "### Batch Size and Epochs\n",
        "The choice of an appropriate batch size and number of epochs is influenced by the optimizer, learning rate, and many other factors. After testing different options, a batch size of 32 and 70 epochs was found to work well. Although 70 epochs might seem high, a technique is used that eventually reduces this number, making the training process more efficient."
      ],
      "metadata": {
        "collapsed": false,
        "id": "bs9kg_oxu2V0"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "base_directory = '/kaggle/input/aiim-emotion-classification/aiim-emotion-classification/'\n",
        "batch_size = 64\n",
        "epochs = 70"
      ],
      "metadata": {
        "id": "mUO6Gqx2u2V0"
      },
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9108 files belonging to 5 classes.\n",
            "Using 7742 files for training.\n",
            "Using 1366 files for validation.\n",
            "['angry', 'fear', 'happy', 'sad', 'surprise']\n"
          ]
        }
      ],
      "source": [
        "# Documentation: https://keras.io/api/data_loading/image/\n",
        "train_ds, validation_ds = image_dataset_from_directory(\n",
        "    directory=base_directory + 'train/',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=420,\n",
        "    subset=\"both\",\n",
        "    validation_split=0.15,\n",
        "    image_size=(100, 100))\n",
        "\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "print(train_ds.class_names)"
      ],
      "metadata": {
        "id": "b7pRo6Cmu2V0",
        "outputId": "40a46a7e-9f2d-44f8-8949-e8cc94a50237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "9u2qytD_u2V0"
      },
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "qM_VVmX3u2V1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ofDIQXbzu2V1"
      }
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_cv\n",
            "  Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/650.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/650.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m553.0/650.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (24.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2024.5.15)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.6)\n",
            "Collecting keras-core (from keras_cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.1)\n",
            "Collecting namex (from keras-core->keras_cv)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (4.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (14.0.2)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n",
            "Requirement already satisfied: etils[enp,epath,epy,etree]>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.7.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->keras_cv) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->keras_cv) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->keras_cv) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2024.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->keras_cv) (0.16)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras_cv\n",
            "Successfully installed keras-core-0.1.7 keras_cv-0.9.0 namex-0.0.8\n",
            "Using TensorFlow backend\n",
            "Found 9108 files belonging to 5 classes.\n",
            "Using 7742 files for training.\n",
            "Using 1366 files for validation.\n",
            "{0: 0.8991869918699187, 1: 1.6419936373276776, 2: 0.9081524926686217, 3: 0.9211183819155264, 4: 0.9156712004730928}\n",
            "['angry', 'fear', 'happy', 'sad', 'surprise']\n",
            "[<keras_cv.src.layers.preprocessing.auto_contrast.AutoContrast object at 0x7932cefb15a0>, <keras_cv.src.layers.preprocessing.equalization.Equalization object at 0x7932cefb05b0>, <keras_cv.src.layers.preprocessing.solarization.Solarization object at 0x7933e2fa56f0>, <keras_cv.src.layers.preprocessing.random_color_degeneration.RandomColorDegeneration object at 0x7932cefb0070>, <keras_cv.src.layers.preprocessing.random_contrast.RandomContrast object at 0x7933e2fa5720>, <keras_cv.src.layers.preprocessing.random_brightness.RandomBrightness object at 0x793241ffc670>, <keras_cv.src.layers.preprocessing.random_shear.RandomShear object at 0x793241ffc940>, <keras_cv.src.layers.preprocessing.random_shear.RandomShear object at 0x793241ffcca0>, <keras_cv.src.layers.preprocessing.random_translation.RandomTranslation object at 0x793241ffcfd0>, <keras_cv.src.layers.preprocessing.random_translation.RandomTranslation object at 0x793241ffd360>]\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_cv\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.applications import ResNet50, ResNet50V2, Xception, EfficientNetB0, EfficientNetB4, ConvNeXtXLarge, ConvNeXtLarge\n",
        "from keras.applications.resnet import preprocess_input\n",
        "from sklearn.utils import class_weight\n",
        "# from keras.applications.efficientnet_v2 import preprocess_input\n",
        "import keras_cv\n",
        "from keras_cv.layers import RandAugment, RandomCutout, RandomChoice\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 70\n",
        "\n",
        "# Documentation: https://keras.io/api/data_loading/image/\n",
        "train_ds, validation_ds = image_dataset_from_directory(\n",
        "    directory=base_directory + 'train/',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=420,\n",
        "    subset=\"both\",\n",
        "    validation_split=0.15,\n",
        "    image_size=(100, 100),\n",
        "    interpolation='bilinear')\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "train_labels = np.concatenate([y.numpy() for x, y in train_ds], axis=0)\n",
        "train_labels = np.argmax(train_labels, axis=1)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(class_weights)\n",
        "\n",
        "print(train_ds.class_names)\n",
        "\n",
        "mix_up = keras_cv.layers.MixUp()\n",
        "\n",
        "cut_mix = keras_cv.layers.CutMix()\n",
        "\n",
        "layers = keras_cv.layers.RandAugment.get_standard_policy(\n",
        "    value_range=(0, 255), magnitude=0.4, magnitude_stddev=0.2,\n",
        ")\n",
        "\n",
        "layers = [\n",
        "    layer for layer in layers if not isinstance(layer, keras_cv.layers.RandomColorDegeneration)\n",
        "]\n",
        "\n",
        "augmenters = [\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    keras_cv.layers.RandomAugmentationPipeline(\n",
        "    layers=layers, augmentations_per_image=3\n",
        "),\n",
        "    RandomCutout(width_factor=0.2, height_factor=0.2),\n",
        "    RandomChoice([cut_mix, mix_up], batchwise=True),\n",
        "]\n",
        "\n",
        "# Since the images are grayscale, we need to convert them to RGB by repeating the grayscale channel\n",
        "def to_rgb(image, label):\n",
        "    image = tf.image.grayscale_to_rgb(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds_rgb = train_ds.map(to_rgb)\n",
        "validation_ds_rgb = validation_ds.map(to_rgb)\n",
        "\n",
        "# Create the augmenter function that processes both image and label\n",
        "def create_augmenter_fn(augmenters):\n",
        "    def augmenter_fn(image, label):\n",
        "        inputs = {\"images\": image, \"labels\": label}\n",
        "        for augmenter in augmenters:\n",
        "            if isinstance(augmenter, (RandomFlip, RandomRotation)):\n",
        "                inputs[\"images\"] = augmenter(inputs[\"images\"])\n",
        "            else:\n",
        "                inputs = augmenter(inputs)\n",
        "        return inputs[\"images\"], inputs[\"labels\"]\n",
        "    return augmenter_fn\n",
        "\n",
        "augmenter_fn = create_augmenter_fn(augmenters)\n",
        "train_ds_preprocessed = train_ds_rgb.map(augmenter_fn)\n",
        "validation_ds_preprocessed = validation_ds_rgb"
      ],
      "metadata": {
        "id": "Z5pVdeKxu2V1",
        "outputId": "23a8cc68-83b3-403e-a05e-5543f427696f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model(base_model):\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(5, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_model(base_model):\n",
        "    model = create_model(base_model)\n",
        "\n",
        "    base_model.trainable = False\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=4, min_lr=0.00001)\n",
        "\n",
        "    model.fit(\n",
        "        train_ds_preprocessed,\n",
        "        validation_data=validation_ds_preprocessed,\n",
        "        epochs=15,\n",
        "        batch_size=batch_size,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers:\n",
        "        if isinstance(layer, BatchNormalization):\n",
        "            layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=9)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=4, min_lr=1e-7)\n",
        "\n",
        "    model.fit(\n",
        "        train_ds_preprocessed,\n",
        "        validation_data=validation_ds_preprocessed,\n",
        "        epochs=100,\n",
        "        batch_size=batch_size,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HwsP5EF9vxfh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "# Erstellen und trainieren der Modelle\n",
        "base_models = [\n",
        "    ConvNeXtLarge(weights='imagenet', include_top=False, input_shape=(100, 100, 3)),\n",
        "    ConvNeXtLarge(weights='imagenet', include_top=False, input_shape=(100, 100, 3)),\n",
        "    ConvNeXtLarge(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "]\n",
        "\n",
        "models = [train_model(base_model) for base_model in base_models]\n",
        "\n",
        "# Bagging durch Durchschnitt der Vorhersagen\n",
        "def bagging_predict(models, dataset):\n",
        "    predictions = np.array([np.argmax(model.predict(dataset), axis=1) for model in models])\n",
        "    majority_vote_predictions = mode(predictions, axis=0)[0][0]\n",
        "    return majority_vote_predictions\n",
        "\n",
        "# Beispielvorhersage auf dem Validierungsdatensatz\n",
        "bagging_predictions = bagging_predict(models, validation_ds_preprocessed)"
      ],
      "metadata": {
        "id": "V0sGBx4Pv-Rc",
        "outputId": "ff21f4b9-ddaf-47e7-b7a5-aaf168fe722b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_large_notop.h5\n",
            "785596384/785596384 [==============================] - 3s 0us/step\n",
            "Epoch 1/15\n",
            "121/121 [==============================] - 74s 434ms/step - loss: 1.7272 - accuracy: 0.3311 - val_loss: 0.9752 - val_accuracy: 0.6369 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "121/121 [==============================] - 42s 343ms/step - loss: 1.5364 - accuracy: 0.4020 - val_loss: 0.8903 - val_accuracy: 0.6794 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "121/121 [==============================] - 41s 339ms/step - loss: 1.4647 - accuracy: 0.4291 - val_loss: 0.8779 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "121/121 [==============================] - 41s 339ms/step - loss: 1.4204 - accuracy: 0.4389 - val_loss: 0.8731 - val_accuracy: 0.6691 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "121/121 [==============================] - 42s 350ms/step - loss: 1.4157 - accuracy: 0.4545 - val_loss: 0.8658 - val_accuracy: 0.6874 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "121/121 [==============================] - 41s 340ms/step - loss: 1.3866 - accuracy: 0.4578 - val_loss: 0.9066 - val_accuracy: 0.6567 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "121/121 [==============================] - 42s 348ms/step - loss: 1.3867 - accuracy: 0.4624 - val_loss: 0.8601 - val_accuracy: 0.6816 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "121/121 [==============================] - 41s 342ms/step - loss: 1.3980 - accuracy: 0.4538 - val_loss: 0.8786 - val_accuracy: 0.6801 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "121/121 [==============================] - 42s 348ms/step - loss: 1.3532 - accuracy: 0.4664 - val_loss: 0.8551 - val_accuracy: 0.6845 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "121/121 [==============================] - 43s 351ms/step - loss: 1.3509 - accuracy: 0.4783 - val_loss: 0.8326 - val_accuracy: 0.6977 - lr: 2.0000e-04\n",
            "Epoch 11/15\n",
            " 28/121 [=====>........................] - ETA: 28s - loss: 1.2903 - accuracy: 0.5039"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-523b49f9b26a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_models\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Bagging durch Durchschnitt der Vorhersagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-523b49f9b26a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_models\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Bagging durch Durchschnitt der Vorhersagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ef18afc262ce>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(base_model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_ds_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_ds_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vorhersagen für die Validierungsdaten\n",
        "y_val_true = np.concatenate([y for x, y in validation_ds_preprocessed], axis=0)\n",
        "y_val_true_classes = np.argmax(y_val_true, axis=1)\n",
        "\n",
        "# Bagging-Vorhersagen berechnen\n",
        "y_val_pred_classes = bagging_predict(models, validation_ds_preprocessed)\n",
        "\n",
        "# F1-Score berechnen\n",
        "f1 = f1_score(y_val_true_classes, y_val_pred_classes, average='weighted')\n",
        "print(\"F1-Score: \", f1)"
      ],
      "metadata": {
        "id": "KM7RzNQWwq2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Confusion Matrix und Classification Report\n",
        "cm = confusion_matrix(y_val_true_classes, y_val_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_val_true_classes, y_val_pred_classes, target_names=class_names))\n"
      ],
      "metadata": {
        "id": "EEwBhPlTu2V2"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Submission"
      ],
      "metadata": {
        "collapsed": false,
        "id": "mzYCMrkQu2V2"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "file_names = []\n",
        "images = []\n",
        "test_directory = base_directory + 'test/'\n",
        "\n",
        "for filename in os.listdir(test_directory):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        img_path = os.path.join(test_directory, filename)\n",
        "        img = load_img(img_path, target_size=(100, 100), color_mode='grayscale', interpolation='bilinear')\n",
        "\n",
        "        # Konvertiere das Bild in ein Tensor\n",
        "        img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "\n",
        "        # Füge eine Dimension für den Graustufenkanal hinzu\n",
        "        img = tf.expand_dims(img, axis=-1)\n",
        "\n",
        "        # Konvertiere das Graustufenbild in ein RGB-Bild\n",
        "        img_array = tf.image.grayscale_to_rgb(img)\n",
        "\n",
        "        images.append(img_array)\n",
        "        file_names.append(filename)\n",
        "\n",
        "# In ein numpy Array konvertieren\n",
        "images_array = np.array(images)\n",
        "\n",
        "\n",
        "# Vorhersagen machen\n",
        "y_test = bagging_predict(models, images_array)\n",
        "\n",
        "y_pred_indices = np.argmax(y_test, axis=1)\n",
        "y_pred_labels = [class_names[idx] for idx in y_pred_indices]\n",
        "\n",
        "# DataFrame erstellen\n",
        "df = pd.DataFrame({\n",
        "    'Id': file_names,\n",
        "    'emotions': y_pred_labels\n",
        "})\n",
        "\n",
        "# DataFrame als CSV speichern\n",
        "df.to_csv('./submission.csv', index=False)"
      ],
      "metadata": {
        "id": "_uOfYoSiu2V2"
      },
      "execution_count": null
    }
  ]
}